# -*- coding: utf-8 -*-
"""CAP4451-Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZGI-_yJ_7rgLq37ls4w5eEyZM_E8SNmW
"""

import numpy as np
import cv2
from matplotlib import pyplot as plt
from google.colab import files
from google.colab.patches import cv2_imshow
from skimage import io
from io import BytesIO
from PIL import Image


#Compute Homography function
def computeH(src,dst):
    m1 = []
    m2 = []
    for i in range(src.shape[0]):
        m1x = [src[i,0],src[i,1],1,0,0,0,-dst[i,0]*src[i,0], -dst[i,0]*src[i,1]]
        m1y = [0,0,0,src[i,0],src[i,1],1,-dst[i,1]*src[i,0], -dst[i,1]*src[i,1]]
        m2x = dst[i,0]
        m2y = dst[i,1]
        m1.append(m1x)
        m1.append(m1y)
        m2.append(m2x)
        m2.append(m2y)

    mult = np.linalg.lstsq(m1,m2)
    H = np.array([[mult[0][0], mult[0][1],mult[0][2]],
                  [mult[0][3], mult[0][4],mult[0][5]],
                  [mult[0][6], mult[0][7], 1 ]])
    return H

#Read images from URL
print("NUMBER 1")
print("\nIn this step we want to find the corners of each image by applying as much functions as we can.\n")
print("\nWe first convert the images to grayscale, then we apply gaussian filter, then we apply OTSU threshold\n")

url =  "https://i.redd.it/bebi64i3kbb31.jpg" #"https://i.ibb.co/Rcw266S/20211027-133244.jpg"
im = io.imread(url)
im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)

url2 = "https://i.ibb.co/dPvVPMx/20211027-133259.jpg" 
im2 = io.imread(url2)
im2 = cv2.cvtColor(im2, cv2.COLOR_BGR2RGB)


print("IMAGE 1\n")
cv2_imshow(im)
print("\nIMAGE 2\n")
cv2_imshow(im2)



#Convert images to grayscale
gray_im = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)
gray_im2 = cv2.cvtColor(im2,cv2.COLOR_BGR2GRAY)

print("\nGRAY IMAGE 1\n")
cv2_imshow(gray_im)
print("\nGRAY IMAGE 2\n")
cv2_imshow(gray_im2)


#Convert images to gaussian blur
blur = cv2.GaussianBlur(gray_im, (5, 5), 0)
blur2 = cv2.GaussianBlur(gray_im2, (5, 5), 0)

print("\nBLUR IMAGE 1\n")
cv2_imshow(blur)
print("\nBLUR IMAGE 2\n")
cv2_imshow(blur2)


#Conver images to threshold OTSU
thresh = cv2.threshold(blur, 0, 299, cv2.THRESH_OTSU)[1]
thresh2 = cv2.threshold(blur2, 0, 299, cv2.THRESH_OTSU)[1]

print("\nTHRESHOLD 1\n")
cv2_imshow(thresh)
print("\nTHRESHOLD 2\n")
cv2_imshow(thresh2)

print("\nThen we find the contours, compute the area of each image, and finally find the contours of each image with the parameters.\n")


#Find contours
cont = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
cont2 = cv2.findContours(thresh2, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

cont = cont[0] if len(cont) == 2 else cont[1]
cont2 = cont2[0] if len(cont2) == 2 else cont2[1]

AT = 0
AT2 = 0

print("\nIn the for loops of the program we pass the contours in the contour area function to find the maximum outline\n")
#The following for loops below are used to find the maximum contours of the image
for i in cont:
    area = cv2.contourArea(i)
    if area > AT:
        AT = area
        MAX_CONT = i

for i in cont2:
    area2 = cv2.contourArea(i)
    if area2 > AT2:
        AT2 = area2
        MAX_CONT2 = i

print("\nWith the maximum contours, we can use opencv arclength to find the perimeters,\n and approxPolyDP to find the corners\n")
#With the MAC_CONTs ready at hand, we can find the perimeter, then use the perimeter to finally find the corners of the image
pm = cv2.arcLength(MAX_CONT, True)
corners = cv2.approxPolyDP(MAX_CONT,0.04*pm,True)

pm2 = cv2.arcLength(MAX_CONT2, True)
corners2 = cv2.approxPolyDP(MAX_CONT2,0.04*pm,True)

#corners printed
print("\nCorner 1: \n")
print("")
print(corners)
print("")

#ask user for input
print("\nEnter the coordinates above from top to bottom\n")


x1, y1 = input("Pick (x1,y1 coordinate): ").split() 

x2, y2 = input("Pick (x2,y2 coordinate): ").split() 

x3, y3 = input("Pick (x3,y3 coordinate): ").split() 

x4, y4 = input("Pick (x4,y4 coordinate): ").split() 

#height and width
height, width, noonecares = im.shape

src = np.array([[x4 , y4], ##Homography implementation works better reversed for some reason
                [x3 , y3],
                [x2 , y2], 
                [x1 , y1]],  np.float32)

dst = np.array([[0,0],
                [width,0],
                [width,height],
                [0,height]], np.float32)


print("\nCorners 2: \n")
print("")
print(corners2)
print("")

print("\nEnter the coordinates above from top to bottom\n")

x21, y21 = input("Pick (x1,y1 coordinate): ").split() 

x22, y22 = input("Pick (x2,y2 coordinate): ").split() 

x23, y23 = input("Pick (x3,y3 coordinate): ").split() 

x24, y24 = input("Pick (x4,y4 coordinate): ").split() 

height2, width2, noonecares2 = im2.shape

src2 = np.array([[x24 , y24 ], ##Homography implementation works better reversed for some reason
                [x23 , y23],
                [x22 , y22], 
                [x21 , y21]],  np.float32)

dst2 = np.array([[0,0],
                [width2,0],
                [width2,height2],
                [0,height2]], np.float32)


print("\nNUMBER 2\n")


print("\nWith the following homography function, we pass the input coordintes and width/height coordinates to get the final homographies\n")
#compute Homography
H = computeH(src,dst)
H2 = computeH(src2,dst2)

print("\nHomography 1: \n")
print(H)

print("\nHomography 2: \n")
print(H2)

print("\nNUMBER 3\n")

print("\nFinally, we use warp perspective to perform warping of the final images\n")
print("\nFINAL WARP 1\n")

#cv2 warp perspective
imwarped = cv2.warpPerspective(im,H,(width,height), cv2.INTER_NEAREST)
cv2_imshow(imwarped)

print("\nFINAL WARP 2\n")
imwarped2 = cv2.warpPerspective(im2,H2,(width2,height2),cv2.INTER_NEAREST)
cv2_imshow(imwarped2)


print("\nConclusion\n")

print("This program works as best as it can to rectify images.\n It worked on the example provided in the project description,\n as well as my own images")
print("\nIf there were anyway to make this program better,\n maybe I should have used the cornerHarris function somehow to find better coordinates for the corners.")
print("\nOverall the results of this project seem adequate.\n")